{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "file_name = \"Dataset.zip\"\n",
    "\n",
    "with ZipFile(file_name, 'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the model\n",
    "classifier = Sequential()\n",
    "\n",
    "# taking 64x64 RGB images as input\n",
    "# 1st conv layer followed by 2x2 maxpooling\n",
    "classifier.add(Conv2D(filters = 64, kernel_size = (5, 5), activation = 'relu', input_shape = (64, 64, 3)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# 2nd conv layer followed by another 2x2 maxpooling\n",
    "classifier.add(Conv2D(filters = 128, kernel_size = (5, 5), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# converting the matrix int vactor\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# 1st fully connected layer\n",
    "classifier.add(Dense(units = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(.5))\n",
    "\n",
    "# 2nd fully connected layer\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dropout(.5))\n",
    "\n",
    "# output layer\n",
    "classifier.add(Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12000 images belonging to 50 classes.\n",
      "Found 3000 images belonging to 50 classes.\n"
     ]
    }
   ],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = .1, rotation_range = 25)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('Dataset/Train', \n",
    "                                                 target_size = (64, 64), \n",
    "                                                 batch_size = 32, \n",
    "                                                 class_mode = 'categorical')\n",
    "test_set = test_datagen.flow_from_directory('Dataset/Test', \n",
    "                                            target_size = (64, 64), \n",
    "                                            batch_size = 32, \n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "100/100 [==============================] - 964s 8s/step - loss: 3.9338 - accuracy: 0.0197 - val_loss: 3.9074 - val_accuracy: 0.0229\n",
      "Epoch 2/15\n",
      "100/100 [==============================] - 301s 3s/step - loss: 3.8749 - accuracy: 0.0338 - val_loss: 3.6148 - val_accuracy: 0.1229\n",
      "Epoch 3/15\n",
      "100/100 [==============================] - 173s 2s/step - loss: 3.5770 - accuracy: 0.0959 - val_loss: 2.8428 - val_accuracy: 0.2906\n",
      "Epoch 4/15\n",
      "100/100 [==============================] - 234s 2s/step - loss: 3.0455 - accuracy: 0.2003 - val_loss: 2.1965 - val_accuracy: 0.4573\n",
      "Epoch 5/15\n",
      "100/100 [==============================] - 123s 1s/step - loss: 2.6799 - accuracy: 0.2700 - val_loss: 1.6606 - val_accuracy: 0.5719\n",
      "Epoch 6/15\n",
      "100/100 [==============================] - 127s 1s/step - loss: 2.3980 - accuracy: 0.3266 - val_loss: 1.4017 - val_accuracy: 0.6271\n",
      "Epoch 7/15\n",
      "100/100 [==============================] - 194s 2s/step - loss: 2.2116 - accuracy: 0.3725 - val_loss: 1.3426 - val_accuracy: 0.6281\n",
      "Epoch 8/15\n",
      "100/100 [==============================] - 149s 1s/step - loss: 2.0494 - accuracy: 0.4091 - val_loss: 1.0816 - val_accuracy: 0.7146\n",
      "Epoch 9/15\n",
      "100/100 [==============================] - 110s 1s/step - loss: 1.9532 - accuracy: 0.4378 - val_loss: 1.0924 - val_accuracy: 0.7052\n",
      "Epoch 10/15\n",
      "100/100 [==============================] - 161s 2s/step - loss: 1.8195 - accuracy: 0.4634 - val_loss: 0.9160 - val_accuracy: 0.7625\n",
      "Epoch 11/15\n",
      "100/100 [==============================] - 177s 2s/step - loss: 1.7931 - accuracy: 0.4791 - val_loss: 1.0336 - val_accuracy: 0.7302\n",
      "Epoch 12/15\n",
      "100/100 [==============================] - 156s 2s/step - loss: 1.6827 - accuracy: 0.5091 - val_loss: 0.9210 - val_accuracy: 0.7521\n",
      "Epoch 13/15\n",
      "100/100 [==============================] - 151s 2s/step - loss: 1.5682 - accuracy: 0.5431 - val_loss: 0.7934 - val_accuracy: 0.7760\n",
      "Epoch 14/15\n",
      "100/100 [==============================] - 148s 1s/step - loss: 1.5341 - accuracy: 0.5547 - val_loss: 0.7884 - val_accuracy: 0.7792\n",
      "Epoch 15/15\n",
      "100/100 [==============================] - 148s 1s/step - loss: 1.4851 - accuracy: 0.5694 - val_loss: 0.7116 - val_accuracy: 0.7844\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "classifier.fit(training_set, steps_per_epoch = 100, epochs = 15,\n",
    "                        validation_data = test_set, validation_steps = 30)\n",
    "\n",
    "\n",
    "# Save the model to disk\n",
    "classifier_json = classifier.to_json()\n",
    "with open(\"LeNetE55.json\", \"w\") as json_file:\n",
    "    json_file.write(classifier_json)\n",
    "    \n",
    "classifier.save_weights(\"LeNetE55.h5\")\n",
    "print('Saved model to disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
